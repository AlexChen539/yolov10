{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cf49972-8d6a-43e6-84b8-da1d8636bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 19 cars, 2 buss, 1 truck, 25.7ms\n",
      "Speed: 3.0ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Annotated image saved to ./images_import/CarsonTheRoad_annotated.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from ultralytics import YOLOv10\n",
    "\n",
    "# 加载模型\n",
    "model = YOLOv10('yolov10n.pt')\n",
    "box_annotator = sv.BoxAnnotator()  # 使用新的 BoxAnnotator 类\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# 修改图片路径，确保路径正确\n",
    "image_path = r'./images_import/CarsOnTheRoad.png'  # 替换为你的图片路径\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# 检查图片是否加载成功\n",
    "if image is None:\n",
    "    print(f\"Failed to load image. Check the file path: {image_path}\")\n",
    "else:\n",
    "    # 执行目标检测\n",
    "    results = model(image)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    # 标记检测到的物体\n",
    "    annotated_image = box_annotator.annotate(\n",
    "        scene=image, detections=detections\n",
    "    )\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=detections\n",
    "    )\n",
    "\n",
    "    # 创建一个窗口显示图片\n",
    "    window_name = \"Object Detection\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)  # 可调整窗口大小\n",
    "    cv2.resizeWindow(window_name, 1280, 720)  # 设置窗口大小\n",
    "    cv2.imshow(window_name, annotated_image)\n",
    "\n",
    "    # 保存标记后的图片\n",
    "    output_path = r'./images_import/CarsonTheRoad_annotated.jpg'\n",
    "    cv2.imwrite(output_path, annotated_image)\n",
    "    print(f\"Annotated image saved to {output_path}\")\n",
    "\n",
    "    # 等待用户按键关闭窗口\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa66904e-d3eb-4c15-ba68-6b0b0875c7a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 6 cars, 1 truck, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6 cars, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7 cars, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7 cars, 12.7ms\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7 cars, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7 cars, 1 truck, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8 cars, 1 truck, 10.6ms\n",
      "Speed: 1.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 cars, 1 truck, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 cars, 1 truck, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 10.6ms\n",
      "Speed: 1.0ms preprocess, 10.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 cars, 1 truck, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 14.1ms\n",
      "Speed: 1.0ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 1 truck, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10 cars, 1 truck, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 truck, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10 cars, 1 truck, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 10 cars, 1 truck, 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 8 cars, 1 truck, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 1 truck, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 1 truck, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 1 truck, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 truck, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 1 truck, 9.6ms\n",
      "Speed: 0.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 1 truck, 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 1 truck, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 1 truck, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 8.5ms\n",
      "Speed: 2.1ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 8 cars, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Video playback stopped by user.\n",
      "Total Detection Count:\n",
      "car: 302\n",
      "person: 67\n",
      "truck: 21\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from ultralytics import YOLOv10\n",
    "from collections import Counter\n",
    "\n",
    "# 加载 YOLOv10 模型（无需 weights_only 参数）\n",
    "model = YOLOv10('yolov10n.pt')\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# 指定视频文件路径或使用摄像头 (0)\n",
    "video_path = r'./images_import/CarVideo.mp4'  # 替换为你的视频文件路径\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 检查视频是否成功打开\n",
    "if not cap.isOpened():\n",
    "    print(f\"Failed to open video. Check the file path: {video_path}\")\n",
    "    exit()\n",
    "\n",
    "# 创建计数器用于统计每种物体的总数\n",
    "total_count = Counter()\n",
    "\n",
    "# 处理视频帧\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # 目标检测\n",
    "    results = model(frame)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    # 提取类别索引，并获取对应的标签名称\n",
    "    class_ids = results.boxes.cls.cpu().numpy().astype(int)\n",
    "    labels = [model.names[id] for id in class_ids]\n",
    "\n",
    "    # 更新总计数\n",
    "    total_count.update(labels)\n",
    "\n",
    "    # 标注检测框和标签\n",
    "    annotated_frame = box_annotator.annotate(\n",
    "        scene=frame, detections=detections\n",
    "    )\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame, detections=detections\n",
    "    )\n",
    "\n",
    "    # 显示标注后的帧\n",
    "    cv2.imshow(\"Video Detection\", annotated_frame)\n",
    "\n",
    "    # 按 'q' 键退出视频播放\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Video playback stopped by user.\")\n",
    "        break\n",
    "\n",
    "# 输出统计结果\n",
    "print(\"Total Detection Count:\")\n",
    "for label, quantity in total_count.items():\n",
    "    print(f\"{label}: {quantity}\")\n",
    "\n",
    "# 释放视频捕获对象并关闭所有窗口\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116feb3b-2637-47c1-a3eb-3996199f9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# SORT 算法实现\n",
    "def linear_assignment(cost_matrix):\n",
    "    try:\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        x, y = linear_sum_assignment(cost_matrix)\n",
    "        return np.array(list(zip(x, y)))\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Install `scipy` for linear sum assignment.\")\n",
    "\n",
    "def iou_batch(bb_test, bb_gt):\n",
    "    bb_gt = np.expand_dims(bb_gt, 0)\n",
    "    bb_test = np.expand_dims(bb_test, 1)\n",
    "    xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "    w = np.maximum(0., xx2 - xx1)\n",
    "    h = np.maximum(0., yy2 - yy1)\n",
    "    wh = w * h\n",
    "    o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])\n",
    "              + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)\n",
    "    return o\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "    w = bbox[2] - bbox[0]\n",
    "    h = bbox[3] - bbox[1]\n",
    "    x = bbox[0] + w / 2.\n",
    "    y = bbox[1] + h / 2.\n",
    "    s = w * h\n",
    "    r = w / float(h)\n",
    "    return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "def convert_x_to_bbox(x, score=None):\n",
    "    w = np.sqrt(x[2] * x[3])\n",
    "    h = x[2] / w\n",
    "    if score is None:\n",
    "        return np.array([x[0] - w / 2., x[1] - h / 2., x[0] + w / 2., x[1] + h / 2.]).reshape((1, 4))\n",
    "    else:\n",
    "        return np.array([x[0] - w / 2., x[1] - h / 2., x[0] + w / 2., x[1] + h / 2., score]).reshape((1, 5))\n",
    "\n",
    "class KalmanBoxTracker(object):\n",
    "    count = 0\n",
    "    def __init__(self, bbox):\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        self.kf.F = np.array([[1, 0, 0, 0, 1, 0, 0],\n",
    "                              [0, 1, 0, 0, 0, 1, 0],\n",
    "                              [0, 0, 1, 0, 0, 0, 1],\n",
    "                              [0, 0, 0, 1, 0, 0, 0],\n",
    "                              [0, 0, 0, 0, 1, 0, 0],\n",
    "                              [0, 0, 0, 0, 0, 1, 0],\n",
    "                              [0, 0, 0, 0, 0, 0, 1]])\n",
    "        self.kf.H = np.array([[1, 0, 0, 0, 0, 0, 0],\n",
    "                              [0, 1, 0, 0, 0, 0, 0],\n",
    "                              [0, 0, 1, 0, 0, 0, 0],\n",
    "                              [0, 0, 0, 1, 0, 0, 0]])\n",
    "        self.kf.R[2:, 2:] *= 10.\n",
    "        self.kf.P[4:, 4:] *= 1000.\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q[-1, -1] *= 0.01\n",
    "        self.kf.Q[4:, 4:] *= 0.01\n",
    "        self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "        self.time_since_update = 0\n",
    "        self.id = KalmanBoxTracker.count\n",
    "        KalmanBoxTracker.count += 1\n",
    "        self.history = []\n",
    "        self.hits = 0\n",
    "        self.hit_streak = 0\n",
    "        self.age = 0\n",
    "\n",
    "    def update(self, bbox):\n",
    "        self.time_since_update = 0\n",
    "        self.history = []\n",
    "        self.hits += 1\n",
    "        self.hit_streak += 1\n",
    "        self.kf.update(convert_bbox_to_z(bbox))\n",
    "\n",
    "    def predict(self):\n",
    "        if (self.kf.x[6] + self.kf.x[2]) <= 0:\n",
    "            self.kf.x[6] *= 0.0\n",
    "        self.kf.predict()\n",
    "        self.age += 1\n",
    "        if self.time_since_update > 0:\n",
    "            self.hit_streak = 0\n",
    "        self.time_since_update += 1\n",
    "        self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "        return self.history[-1]\n",
    "\n",
    "    def get_state(self):\n",
    "        return convert_x_to_bbox(self.kf.x)\n",
    "def associate_detections_to_trackers(detections, trackers, iou_threshold=0.3):\n",
    "    if (len(trackers) == 0):\n",
    "        return np.empty((0, 2), dtype=int), np.arange(len(detections)), np.empty((0, 5), dtype=int)\n",
    "\n",
    "    iou_matrix = iou_batch(detections, trackers)\n",
    "\n",
    "    if min(iou_matrix.shape) > 0:\n",
    "        a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "        if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "            matched_indices = np.stack(np.where(a), axis=1)\n",
    "        else:\n",
    "            matched_indices = linear_assignment(-iou_matrix)\n",
    "    else:\n",
    "        matched_indices = np.empty(shape=(0, 2))\n",
    "\n",
    "    unmatched_detections = []\n",
    "    for d, det in enumerate(detections):\n",
    "        if (d not in matched_indices[:, 0]):\n",
    "            unmatched_detections.append(d)\n",
    "    unmatched_trackers = []\n",
    "    for t, trk in enumerate(trackers):\n",
    "        if (t not in matched_indices[:, 1]):\n",
    "            unmatched_trackers.append(t)\n",
    "\n",
    "    matches = []\n",
    "    for m in matched_indices:\n",
    "        if (iou_matrix[m[0], m[1]] < iou_threshold):\n",
    "            unmatched_detections.append(m[0])\n",
    "            unmatched_trackers.append(m[1])\n",
    "        else:\n",
    "            matches.append(m.reshape(1, 2))\n",
    "    if (len(matches) == 0):\n",
    "        matches = np.empty((0, 2), dtype=int)\n",
    "    else:\n",
    "        matches = np.concatenate(matches, axis=0)\n",
    "\n",
    "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "class Sort(object):\n",
    "    def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n",
    "        self.max_age = max_age\n",
    "        self.min_hits = min_hits\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.trackers = []\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def update(self, dets=np.empty((0, 5))):\n",
    "        self.frame_count += 1\n",
    "        trks = np.zeros((len(self.trackers), 5))\n",
    "        to_del = []\n",
    "        ret = []\n",
    "        for t, trk in enumerate(trks):\n",
    "            pos = self.trackers[t].predict()[0]\n",
    "            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "            if np.any(np.isnan(pos)):\n",
    "                to_del.append(t)\n",
    "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "        for t in reversed(to_del):\n",
    "            self.trackers.pop(t)\n",
    "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets, trks, self.iou_threshold)\n",
    "        for m in matched:\n",
    "            self.trackers[m[1]].update(dets[m[0], :])\n",
    "        for i in unmatched_dets:\n",
    "            trk = KalmanBoxTracker(dets[i, :])\n",
    "            self.trackers.append(trk)\n",
    "        i = len(self.trackers)\n",
    "        for trk in reversed(self.trackers):\n",
    "            d = trk.get_state()[0]\n",
    "            if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "                ret.append(np.concatenate((d, [trk.id + 1])).reshape(1, -1))\n",
    "            i -= 1\n",
    "            if trk.time_since_update > self.max_age:\n",
    "                self.trackers.pop(i)\n",
    "        if len(ret) > 0:\n",
    "            return np.concatenate(ret)\n",
    "        return np.empty((0, 5))\n",
    "\n",
    "# 主逻辑整合 YOLO 和 SORT\n",
    "model = YOLO('yolov8n.pt')\n",
    "vehicle_classes = ['car', 'truck', 'bus', 'motorcycle']\n",
    "tracker = Sort(max_age=3, min_hits=3, iou_threshold=0.3)\n",
    "cap = cv2.VideoCapture('./images_import/CarVideo.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_video = cv2.VideoWriter(\n",
    "    'output_with_vehicle_count.mp4',\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "vehicle_count = set()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = model(frame_rgb)\n",
    "    detections = results[0]\n",
    "    bboxes = detections.boxes.xyxy.cpu().numpy()\n",
    "    scores = detections.boxes.conf.cpu().numpy()\n",
    "    class_ids = detections.boxes.cls.cpu().numpy().astype(int)\n",
    "    vehicle_detections = []\n",
    "    for bbox, score, class_id in zip(bboxes, scores, class_ids):\n",
    "        if model.names[class_id] in vehicle_classes:\n",
    "            vehicle_detections.append(np.append(bbox, score))\n",
    "    vehicle_detections = np.array(vehicle_detections)\n",
    "    tracks = tracker.update(vehicle_detections)\n",
    "    for track in tracks:\n",
    "        x1, y1, x2, y2, track_id = track.astype(int)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"ID {track_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        vehicle_count.add(track_id)\n",
    "    cv2.putText(frame, f\"Total Vehicles: {len(vehicle_count)}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow('Vehicle Tracking', frame)\n",
    "    output_video.write(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Total unique vehicles: {len(vehicle_count)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af342fc-665c-4964-925c-6b95408c10dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
